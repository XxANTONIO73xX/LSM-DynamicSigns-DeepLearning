{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64681f17",
   "metadata": {},
   "source": [
    "# Optimization of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from Helpers.data import Data\n",
    "from Helpers.models import Models\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841682be",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters=128, stride=2):\n",
    "    # Ejemplo simplificado: conv->bn->relu->conv->add->bn->relu->maxpool\n",
    "    shortcut = x\n",
    "    \n",
    "    out = keras.layers.Conv1D(filters, stride, padding='same')(x)\n",
    "    out = keras.layers.BatchNormalization()(out)\n",
    "    out = keras.layers.ReLU()(out)\n",
    "    \n",
    "    out = keras.layers.Conv1D(filters, stride, padding='same')(out)\n",
    "    out = keras.layers.Add()([shortcut, out])\n",
    "    out = keras.layers.BatchNormalization()(out)\n",
    "    out = keras.layers.ReLU()(out)\n",
    "    out = keras.layers.MaxPool1D(pool_size=2, strides=2)(out)\n",
    "    return out\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Crea un modelo Keras “similar” a tu customResNet,\n",
    "    con hiperparámetros ajustables (HP).\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = keras.Input(shape=(15,114))\n",
    "\n",
    "    # 1) Conv inicial (fijo en este ejemplo)\n",
    "    x = keras.layers.Conv1D(128, 2)(inputs)\n",
    "\n",
    "    # 2) Tres bloques residuales (similar a customResNet).\n",
    "    #    Podríamos incorporar hiperparámetros aquí también (e.g. # de bloques).\n",
    "    for i in range(3):\n",
    "        x = residual_block(x, filters=128, stride=2)\n",
    "\n",
    "    # 3) Flatten\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    # 4) Añadimos capas densas con hiperparámetros\n",
    "    # p.ej. n_capas_densas y dropout:\n",
    "    n_capas = hp.Int(\"n_capas_densas\", min_value=1, max_value=3)\n",
    "    for i in range(n_capas):\n",
    "        units = hp.Choice(f\"units_dense_{i}\", [64,128,256])\n",
    "        x = keras.layers.Dense(units, activation='relu')(x)\n",
    "        # dropout\n",
    "        rate = hp.Float(f\"dropout_{i}\", min_value=0.0, max_value=0.8, step=0.1)\n",
    "        x = keras.layers.Dropout(rate)(x)\n",
    "\n",
    "    # 5) Capa de salida (número de clases a tu elección)\n",
    "    num_classes = 122\n",
    "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"MyResnet1D\")\n",
    "\n",
    "    # 6) Definir la tasa de aprendizaje como hiperparámetro\n",
    "    lr = hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[F1Score(num_classes=num_classes, average='macro')]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6134a98",
   "metadata": {},
   "source": [
    "## Optimization search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e15d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_search(data_obj, dir_path, subjects_array):\n",
    "    f1_results = []  # almacenar F1 final por sujeto\n",
    "\n",
    "    for sub in tqdm(subjects_array, desc=\"Procesando sujetos\", unit=\"sujeto\"):\n",
    "        train_data, test_data = data_obj.LeaveOneOutExp1(sub)\n",
    "\n",
    "        if len(train_data) == 0 or len(test_data) == 0:\n",
    "            print(f\"[ADVERTENCIA] Sujeto {sub}: sin datos, se omite.\")\n",
    "            continue\n",
    "\n",
    "        X_train, y_train = data_obj.SplitXandY(train_data)\n",
    "        X_test, y_test   = data_obj.SplitXandY(test_data)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    "        )\n",
    "\n",
    "        (y_train_enc, y_val_enc, y_test_enc), le = data_obj.EncodeLabels([y_train, y_val, y_test])\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        n_classes   = y_train_enc.shape[1]  # asume one-hot => (samples, n_classes)\n",
    "        class_names = le.classes_\n",
    "        labels = np.arange(len(class_names))\n",
    "        y_true = y_test_enc.argmax(axis=1)\n",
    "\n",
    "        # Definir tuner con la métrica 'val_f1' (expuesta por la custom metric)\n",
    "        tuner = kt.RandomSearch(\n",
    "            build_model,                 # la función que construye el modelo\n",
    "            objective=kt.Objective('val_f1_score', direction='max'),          # métrica a optimizar\n",
    "            max_trials=10,\n",
    "            executions_per_trial=1,\n",
    "            directory=dir_path,\n",
    "            project_name=f\"resnet_opt_{sub}\"\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            X_train, y_train_enc,\n",
    "            validation_data=(X_val, y_val_enc),\n",
    "            epochs=25,\n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "        best_model = tuner.hypermodel.build(best_hp)\n",
    "        best_model.fit(\n",
    "            X_train, y_train_enc,\n",
    "            validation_data=(X_val, y_val_enc),\n",
    "            epochs=25, \n",
    "            batch_size=32,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Evaluar en el test con 'model.evaluate' => [loss, f1]\n",
    "        results = best_model.evaluate(X_test, y_test_enc, verbose=0)\n",
    "        # Por definicion: results[0] = loss, results[1] = f1 (la segunda métrica)\n",
    "        test_loss, test_f1 = results[0], results[1]\n",
    "\n",
    "        f1_results.append(test_f1)\n",
    "\n",
    "        # Guardar si deseas\n",
    "        best_model.save(f\"./{dir_path}/resnet_opt_{sub}/best_model.h5\")\n",
    "\n",
    "        y_pred_probs = best_model.predict(X_test, batch_size=32, verbose=0)\n",
    "        y_pred = y_pred_probs.argmax(axis=1)\n",
    "        report = classification_report(y_true, y_pred, labels=labels, target_names=class_names, zero_division=0, output_dict=True)\n",
    "        f1_acc = report['macro avg']['f1-score']\n",
    "\n",
    "        with open(f\"./{dir_path}/resnet_opt_{sub}/outputs.txt\", \"w\") as f:\n",
    "            print(best_hp.values, file=f)\n",
    "            print(f\"Sujeto {sub}: Test F1 = {test_f1:.3f}, Loss = {test_loss:.3f}\", file=f)\n",
    "            print(f\"Calculado con Classification_report: F1-score = {f1_acc:.3f}\", file=f)\n",
    "\n",
    "\n",
    "\n",
    "    # Al final, calculas promedio y desviación estándar de F1:\n",
    "    return np.array(f1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7440a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/Dataset.csv\")\n",
    "data_obj = Data(df=df)\n",
    "subjects_array = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91601a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_results = optimization_search(data_obj=data_obj, dir_path=f\"./Op results\", subjects_array=subjects_array)\n",
    "subject_scores = {f\"Sub_{i+1}\": f1 for i, f1 in enumerate(f1_results)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7210a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
